# LookaheadRAG Default Configuration
# Override via environment variables or command-line args

# Random seed for reproducibility
seed: 42

# === LLM Configuration ===
llm:
  # Using Groq free tier for better performance
  provider: groq  # ollama | groq | google
  
  ollama:
    host: ${OLLAMA_HOST:http://localhost:11434}
    planner_model: llama3.2:3b
    synthesizer_model: llama3.2:3b
    temperature: 0.1
    max_tokens: 2048
  
  groq:
    api_key: ${GROQ_API_KEY:}
    # HIGH QUALITY MODE: Using 70B for synthesis
    planner_model: llama-3.1-8b-instant
    synthesizer_model: llama-3.3-70b-versatile  # Best quality answers
    temperature: 0.1
    max_tokens: 2048
  
  google:
    api_key: ${GOOGLE_API_KEY:}
    model: gemini-1.5-flash
    temperature: 0.1
    max_tokens: 2048

# === Embedding Configuration ===
embedding:
  model: all-MiniLM-L6-v2
  batch_size: 32
  normalize: true

# === Reranker Configuration ===
reranker:
  model: cross-encoder/ms-marco-MiniLM-L6-v2
  top_k: 10
  threshold: 0.5

# === Vector Store Configuration ===
vector_store:
  provider: chromadb  # chromadb | faiss
  persist_dir: ./data/chroma_db
  collection_name: hotpotqa_wiki

# === Planner Configuration ===
planner:
  max_nodes: 5
  min_nodes: 2
  confidence_threshold: 0.3
  
  # Self-consistency for confidence estimation
  self_consistency:
    enabled: true
    num_samples: 3
    agreement_threshold: 0.6

# === Retrieval Configuration ===
retrieval:
  top_k: 5
  max_parallel_queries: 5
  timeout_seconds: 30
  
  # Chunk settings
  chunk_size: 512
  chunk_overlap: 50

# === Context Assembly ===
context:
  max_tokens: 4096
  dedup_threshold: 0.85  # Jaccard similarity for deduplication
  compression:
    enabled: true
    target_ratio: 0.5

# === Budgeted Pruning ===
pruning:
  enabled: true
  max_budget: 10
  utility_weights:
    confidence: 0.4
    novelty: 0.3
    hop_coverage: 0.3

# === Fallback Configuration ===
fallback:
  enabled: true
  triggers:
    low_coverage_threshold: 2  # Min relevant chunks
    high_entropy_threshold: 1.5
  max_additional_steps: 2

# === Evaluation Configuration ===
evaluation:
  datasets:
    - hotpotqa
    - 2wikimultihopqa
  
  metrics:
    - exact_match
    - f1
    - supporting_fact_f1
    - latency_p50
    - latency_p95
    - num_llm_calls
    - total_tokens
  
  subset_size: 500  # For quick iteration
  
# === Logging ===
logging:
  level: INFO
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: ./logs/lookahead_rag.log
