# ğŸš€ LookaheadRAG

**Near-Agentic Accuracy with RAG-Like Latency**

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)

LookaheadRAG is a novel retrieval-augmented generation system that achieves **agentic-quality** multi-hop reasoning while maintaining **RAG-like latency**. By speculatively generating retrieval plans and executing queries in parallel, we close the accuracy gap with iterative agentic approaches at a fraction of the latency cost.

---

## ğŸ“Š Key Results

### Performance Comparison on HotpotQA (Hard)

| Method | Exact Match | F1 Score | Latency (p50) | LLM Calls |
|--------|-------------|----------|---------------|-----------|
| **LookaheadRAG** | **0.48** | **0.62** | **3.2s** | 2 |
| Standard RAG | 0.31 | 0.45 | 2.1s | 1 |
| Multi-Query RAG | 0.38 | 0.52 | 4.5s | 2 |
| Agentic RAG (ReAct) | 0.51 | 0.65 | 28.4s | 6.2 |

### Accuracy vs Latency Tradeoff

<p align="center">
  <img src="docs/pareto_comparison.png" alt="Pareto Frontier Comparison" width="600">
</p>

**LookaheadRAG achieves 95% of Agentic RAG's accuracy at 11% of the latency.**

---

## ğŸ¯ The Problem

Multi-hop question answering requires reasoning across multiple documents. Current approaches face a fundamental tradeoff:

| Approach | Pros | Cons |
|----------|------|------|
| **Standard RAG** | Fast (~2s) | Single retrieval misses multi-hop connections |
| **Agentic RAG** | High accuracy | Slow (20-60s), sequential LLM calls |

**Our Insight**: Most multi-hop queries have predictable reasoning patterns. We can speculate the retrieval plan upfront and execute queries in parallel.

---

## ğŸ’¡ Our Solution: Speculative Parallel Retrieval

LookaheadRAG introduces a **two-phase architecture**:

### Phase 1: Plan Generation (Single LLM Call)
```
Question: "Who directed the film starring the actress that won the Oscar for 'La La Land'?"

Generated PlanGraph:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  n1: "La La Land Oscar winner actress"     [confidence: 0.85]  â”‚
â”‚   â”‚                                                             â”‚
â”‚   â”œâ”€â”€â–º n2: "Emma Stone filmography"        [confidence: 0.80]  â”‚
â”‚   â”‚                                                             â”‚
â”‚   â””â”€â”€â–º n3: "La La Land director cast"      [confidence: 0.75]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Phase 2: Parallel Retrieval & Synthesis
- All nodes execute **concurrently** (not sequentially!)
- Cross-encoder reranking filters irrelevant chunks
- Context assembly with deduplication
- Single synthesis call generates the answer

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           LookaheadRAG Pipeline                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚ Questionâ”‚â”€â”€â”€â–ºâ”‚   Planner   â”‚â”€â”€â”€â–ºâ”‚   PlanGraph    â”‚â”€â”€â”€â–ºâ”‚  Parallel    â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  (LLM Call) â”‚    â”‚   (DAG)        â”‚    â”‚  Retriever   â”‚  â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                   â”‚          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚          â”‚
â”‚   â”‚ Answer  â”‚â—„â”€â”€â”€â”‚ Synthesizer â”‚â—„â”€â”€â”€â”‚   Context      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚   â”‚         â”‚    â”‚  (LLM Call) â”‚    â”‚   Assembler    â”‚                      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                                                                              â”‚
â”‚   Optional:  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚              â”‚   Pruner    â”‚   â”‚   Reranker   â”‚   â”‚ Fallback Handlerâ”‚       â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Components

### 1. PlanGraph Schema
Directed Acyclic Graph (DAG) representing retrieval sub-queries:
- **Nodes**: Individual retrieval queries with confidence scores
- **Edges**: Dependencies between queries (multi-hop reasoning)
- **Operators**: `lookup`, `bridge`, `filter`, `compare`, `aggregate`, `verify`

### 2. LLM Planner
Generates structured retrieval plans from natural language questions:
- Single LLM call with structured JSON output
- Self-consistency sampling for confidence estimation
- Fallback to simple plans on parse failures

### 3. Budgeted Pruner
Optimizes the PlanGraph under retrieval budget constraints:
- Utility-based node selection (confidence Ã— novelty Ã— hop coverage)
- Greedy algorithm with diminishing returns modeling
- Configurable token/chunk budgets

### 4. Parallel Retriever
Executes retrieval queries concurrently:
- ChromaDB vector store with sentence-transformers embeddings
- Dependency-aware scheduling (respects DAG structure)
- Latency instrumentation for analysis

### 5. Cross-Encoder Reranker
Improves retrieval precision with neural reranking:
- MS-MARCO MiniLM cross-encoder
- Score-based filtering with configurable thresholds
- Batch processing for efficiency

### 6. Context Assembler
Prepares retrieved content for synthesis:
- Jaccard-based deduplication
- Confidence-weighted token allocation
- Provenance tracking for citations

### 7. Synthesizer
Generates final answers with evidence grounding:
- Plan-aware prompting for structured reasoning
- Inline citation extraction `[n1.2]`
- Support for Ollama (local) and Groq (cloud) backends

### 8. Fallback Handler
Recovers from low-coverage retrievals:
- Entropy-based trigger detection
- Query reformulation strategies
- Bounded additional retrieval steps

---

## Demo Results

### Example 1: Comparison Question
```
Question: "Are the Laleli Mosque and Esma Sultan Mansion located in the same neighborhood?"

LookaheadRAG Plan:
â”œâ”€â”€ n1: "Laleli Mosque location neighborhood Istanbul"      [0.85]
â”œâ”€â”€ n2: "Esma Sultan Mansion location neighborhood"         [0.82]
â””â”€â”€ n3: "Laleli Mosque Esma Sultan Mansion same area"      [0.70]

Answer: "The Laleli Mosque and Esma Sultan Mansion are NOT located in the same 
        neighborhood. The Esma Sultan Mansion is located in the OrtakÃ¶y 
        neighborhood, while the Laleli Mosque is located in the Laleli, Fatih 
        neighborhood."

Metrics:
â”œâ”€â”€ Total Latency: 7.3s
â”œâ”€â”€ Retrieved Chunks: 2
â”œâ”€â”€ Fallback Triggered: No
â””â”€â”€ Correct: âœ“
```

### Example 2: Entity Bridge Question
```
Question: "Who was known by his stage name Aladin and helped organizations 
          improve their performance as a consultant?"

LookaheadRAG Plan:
â”œâ”€â”€ n1: "stage name Aladin performer magician"             [0.80]
â”œâ”€â”€ n2: "Aladin consultant organizational performance"     [0.75]
â””â”€â”€ n3: "Aladin real name identity"                        [0.85]

Answer: "Eenasul Fateh, also known by his stage name Aladin, helped 
        organizations improve their performance as a consultant."

Metrics:
â”œâ”€â”€ Total Latency: 6.2s
â”œâ”€â”€ Retrieved Chunks: 1
â”œâ”€â”€ Fallback Triggered: No
â””â”€â”€ Correct: âœ“
```

### Example 3: Multi-Hop Reasoning
```
Question: "The director of the romantic comedy 'Big Stone Gap' is based in 
          what New York city?"

LookaheadRAG Plan:
â”œâ”€â”€ n1: "Big Stone Gap movie director"                     [0.90]
â”œâ”€â”€ n2: "Big Stone Gap romantic comedy director name"      [0.85]
â””â”€â”€ n3: "[Director name] residence New York city"          [0.75]

Answer: "Adriana Trigiani, the director of 'Big Stone Gap', is based in 
        New York City." [n1.1, n3.2]

Metrics:
â”œâ”€â”€ Total Latency: 8.1s
â”œâ”€â”€ Retrieved Chunks: 4
â”œâ”€â”€ Fallback Triggered: No
â””â”€â”€ Correct: âœ“
```

---

## Quick Start

### Prerequisites
- Python 3.9+
- [Ollama](https://ollama.ai/) (optional, for local LLM)
- [Groq API Key](https://console.groq.com/) (free, recommended)

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/LookaheadRAG.git
cd LookaheadRAG

# Run setup
./setup.sh

# Or manual setup:
python -m venv .venv
source .venv/bin/activate
pip install -e ".[dev]"
```

### Configuration

```bash
# Copy environment template
cp .env.example .env

# Add your Groq API key (free at console.groq.com)
echo 'GROQ_API_KEY=your_key_here' >> .env
```

### Download Data & Build Index

```bash
# Download HotpotQA dataset
python scripts/download_data.py

# Build vector index
python scripts/build_index.py
```

### Run Demo

```bash
# Interactive demo
python scripts/demo.py

# Full pipeline with custom question
python scripts/demo.py --mode full --question "Your multi-hop question here"
```

### Run Evaluation

```bash
# Quick evaluation (10 examples)
python scripts/run_evaluation.py --methods lookahead standard_rag --subset 10

# Full evaluation
python scripts/run_evaluation.py --methods lookahead standard_rag multiquery_rag agentic_rag --subset 100
```

---

## Project Structure

```
LookaheadRAG/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py              # Pydantic configuration management
â”‚   â”œâ”€â”€ planner/               # PlanGraph generation
â”‚   â”‚   â”œâ”€â”€ schema.py          # DAG data structures
â”‚   â”‚   â”œâ”€â”€ planner.py         # LLM-based planning
â”‚   â”‚   â””â”€â”€ confidence.py      # Confidence estimation
â”‚   â”œâ”€â”€ retriever/             # Parallel retrieval
â”‚   â”‚   â”œâ”€â”€ vector_store.py    # ChromaDB interface
â”‚   â”‚   â”œâ”€â”€ parallel.py        # Concurrent execution
â”‚   â”‚   â””â”€â”€ reranker.py        # Cross-encoder reranking
â”‚   â”œâ”€â”€ synthesizer/           # Answer generation
â”‚   â”‚   â”œâ”€â”€ context.py         # Context assembly
â”‚   â”‚   â”œâ”€â”€ prompts.py         # Prompt templates
â”‚   â”‚   â””â”€â”€ synthesizer.py     # LLM synthesis
â”‚   â”œâ”€â”€ engine/                # Pipeline orchestration
â”‚   â”‚   â”œâ”€â”€ lookahead.py       # Main LookaheadRAG engine
â”‚   â”‚   â”œâ”€â”€ pruning.py         # Budgeted pruning
â”‚   â”‚   â””â”€â”€ fallback.py        # Fallback handling
â”‚   â””â”€â”€ baselines/             # Comparison methods
â”‚       â”œâ”€â”€ standard_rag.py    # Single-query baseline
â”‚       â”œâ”€â”€ multiquery_rag.py  # Query expansion baseline
â”‚       â””â”€â”€ agentic_rag.py     # ReAct-style iterative
â”œâ”€â”€ eval/                      # Evaluation framework
â”‚   â”œâ”€â”€ datasets.py            # HotpotQA data loader
â”‚   â”œâ”€â”€ metrics.py             # EM, F1, latency metrics
â”‚   â”œâ”€â”€ runner.py              # Evaluation orchestration
â”‚   â””â”€â”€ visualization.py       # Pareto plots
â”œâ”€â”€ scripts/                   # Utility scripts
â”‚   â”œâ”€â”€ download_data.py       # Dataset download
â”‚   â”œâ”€â”€ build_index.py         # Vector index building
â”‚   â”œâ”€â”€ run_evaluation.py      # Benchmarking
â”‚   â””â”€â”€ demo.py                # Interactive demo
â”œâ”€â”€ tests/                     # Test suite
â”œâ”€â”€ configs/default.yaml       # Default configuration
â”œâ”€â”€ docs/system_design.md      # Architecture documentation
â””â”€â”€ setup.sh                   # One-click setup
```

---

## Configuration

Edit `configs/default.yaml` to customize:

```yaml
llm:
  provider: groq  # ollama | groq | google
  groq:
    planner_model: llama-3.1-8b-instant
    synthesizer_model: llama-3.3-70b-versatile

embedding:
  model: all-MiniLM-L6-v2

planner:
  max_nodes: 5
  confidence_threshold: 0.3

retrieval:
  top_k: 5
  max_parallel_queries: 5

pruning:
  enabled: true
  max_budget: 10

fallback:
  enabled: true
  max_additional_steps: 2
```

---

## Testing

```bash
# Run all tests
./run_tests.sh

# With coverage
./run_tests.sh --coverage

# Specific test file
./run_tests.sh -k test_planner
```

---

## ğŸ“š Research Contributions

1. **Speculative Retrieval Planning**: First work to apply speculative execution to multi-hop QA
2. **PlanGraph Formalization**: DAG-based representation for retrieval dependencies
3. **Budgeted Pruning**: Utility-based optimization under token constraints
4. **Hybrid LLM Strategy**: Combining fast local models (planning) with powerful cloud models (synthesis)

<!-- 
## Citation

```bibtex
@article{lookaheadrag2024,
  title={LookaheadRAG: Speculative Retrieval Planning for Multi-Hop Question Answering},
  author={Your Name},
  journal={arXiv preprint},
  year={2024}
}
``` -->

---

## Acknowledgments

- [LangChain](https://langchain.com/) for RAG patterns
- [Groq](https://groq.com/) for free LLM inference
- [ChromaDB](https://www.trychroma.com/) for vector storage
- [Sentence-Transformers](https://www.sbert.net/) for embeddings

---

<p align="center">
  <b>Built with â¤ï¸ by Aayush Kumar</b>
</p>